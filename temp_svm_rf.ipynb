{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Support Vector Machines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_importance_dict = {}\n",
    "mse_dict = {}\n",
    "perf_metrics = {}\n",
    "for key, value in df_dict.items():\n",
    "    df = value.drop(['SEQN','Year'], axis=1)\n",
    "    X = df.drop('Diabetes', axis=1)\n",
    "    y = df[['Diabetes']]\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "    #reshape y_train to be a column vector\n",
    "    y_train = y_train.values.ravel()\n",
    "    ##Support Vector Machines\n",
    "    svm = SVC(max_iter=100)\n",
    "    pipe = Pipeline([('scaler',StandardScaler()),('svm', svm)])\n",
    "    #param_grid = {'svm__C': np.logspace(-3, 3, 7)}\n",
    "    param_grid = {'svm__C': [0.01, 0.1]}\n",
    "    svm_model = GridSearchCV(pipe, param_grid, cv=5)\n",
    "    svm_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This creates a logistic regression model for each cycle and storing the feature importances, MSEs in a dictionary\n",
    "\n",
    "feature_importance_dict = {}\n",
    "mse_dict = {}\n",
    "perf_metrics = {}\n",
    "for key, value in df_dict.items():\n",
    "    df = value.drop(['SEQN','Year'], axis=1)\n",
    "    X = df.drop('Diabetes', axis=1)\n",
    "    y = df[['Diabetes']]\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "    #reshape y_train to be a column vector\n",
    "    y_train = y_train.values.ravel()\n",
    "    ##Support Vector Machines\n",
    "    svm = SVC(max_iter=100)\n",
    "    pipe = Pipeline([('scaler',StandardScaler()),('svm', svm)])\n",
    "    #param_grid = {'svm__C': np.logspace(-3, 3, 7)}\n",
    "    param_grid = {'svm__C': [0.01, 0.1]}\n",
    "    svm_model = GridSearchCV(pipe, param_grid, cv=5)\n",
    "    svm_model.fit(X_train, y_train)\n",
    "    #feature importance\n",
    "    feature_import = abs(logistic_model.best_estimator_.steps[0][1].coef_)\n",
    "    feature_import = 100 * feature_import / feature_import.sum()\n",
    "    feature_import[0]\n",
    "    feature_importance_dict[key] = feature_import[0]\n",
    "    mse_dict[key] = {'Train MSE': round(mean_squared_error(y_train,logistic_model.predict(X_train)),4),\n",
    "                    'Test MSE': round(mean_squared_error(y_test,logistic_model.predict(X_test)),4)}\n",
    "    perf_metrics[key] = {'F1': round(f1_score(y_test,logistic_model.predict(X_test)),4),\n",
    "                        'Precision': round(precision_score(y_test,logistic_model.predict(X_test)),4),\n",
    "                        'Recall': round(recall_score(y_test,logistic_model.predict(X_test)),4)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Support Vector Machines\n",
    "#svm = SVC(max_iter=1000)\n",
    "#pipe = Pipeline([('svm', svm)])\n",
    "#param_grid = {'svm__C': np.logspace(-3, 3, 7)}\n",
    "#svm_model = GridSearchCV(pipe, param_grid, cv=5)\n",
    "#svm_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Support Vector Machines\n",
    "#print(svm_model.best_params_)\n",
    "#print(svm_model.best_score_)\n",
    "#print(svm_model.best_estimator_)\n",
    "#\n",
    "##performance\n",
    "#print('Train set performance: ' + str(round(mean_squared_error(y_train,svm_model.predict(X_train)),4))) #Train set prediction and performance\n",
    "#print('Test set performance: ' + str(round(mean_squared_error(y_test,svm_model.predict(X_test)),4))) #Test set prediction and performance\n",
    "#\n",
    "##Predictions\n",
    "#svm_y_pred = svm_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Random Forest\n",
    "#rf = RandomForestClassifier(n_estimators=100, max_depth=5, random_state=0)\n",
    "#pipe = Pipeline([('scaler', scaler),('rf', rf)])\n",
    "#param_grid = {'rf__max_depth': [3, 5, 7], 'rf__n_estimators': [100, 200, 300]}\n",
    "#rf_model = GridSearchCV(pipe, param_grid, cv=5)\n",
    "#rf_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Random Forest\n",
    "#print(rf_model.best_params_)\n",
    "#print(rf_model.best_score_)\n",
    "#print(rf_model.best_estimator_)\n",
    "#\n",
    "##performance\n",
    "#print('Train set performance: ' + str(round(mean_squared_error(y_train,rf_model.predict(X_train)),4))) #Train set prediction and performance\n",
    "#print('Test set performance: ' + str(round(mean_squared_error(y_test,rf_model.predict(X_test)),4))) #Test set prediction and performance\n",
    "#\n",
    "##Predictions\n",
    "#rf_y_pred = rf_model.predict(X_test)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
